{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "287cfd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5050803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[63.,  1.,  1., ...,  0.,  6.,  0.],\n",
       "       [67.,  1.,  4., ...,  3.,  3.,  2.],\n",
       "       [67.,  1.,  4., ...,  2.,  7.,  1.],\n",
       "       ...,\n",
       "       [68.,  1.,  4., ...,  2.,  7.,  2.],\n",
       "       [57.,  1.,  4., ...,  1.,  7.,  3.],\n",
       "       [57.,  0.,  2., ...,  1.,  3.,  1.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawData = np.loadtxt('final_cleveland - no_title.csv' , delimiter=',')\n",
    "rawData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e653e7f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
       "       0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0.,\n",
       "       1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
       "       1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
       "       1., 0., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawInputs = rawData[ : , 1:-1 ] #از ستون 1 تا یکی مونده به اخر\n",
    "rawTargets = rawData[ : , -1]#\n",
    "rawTargets = np.where(rawTargets == 0, 0,\n",
    "                      np.where(rawTargets == 1, 1 ,\n",
    "                        np.where(rawTargets == 2, 1 ,\n",
    "                         np.where(rawTargets == 3, 1 ,\n",
    "                          np.where(rawTargets == 4, 1 ,\n",
    "                              rawTargets)))))\n",
    "rawTargets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d0b1920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137 160\n"
     ]
    }
   ],
   "source": [
    "numberOfOneTargets = int(np.sum(rawTargets))\n",
    "numberOfZeroTargets = int( rawTargets.shape[0] - np.sum(rawTargets))\n",
    "print( numberOfOneTargets , numberOfZeroTargets )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4887dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeros are : 160 and we should remove 23 indexes to balancing dataset\n"
     ]
    }
   ],
   "source": [
    "indexesToRemove = []\n",
    "numberOfZeroTargets = 0\n",
    "\n",
    "for i in range(rawTargets.shape[0]):\n",
    "    if ( rawTargets[i] == 0):\n",
    "        numberOfZeroTargets +=1\n",
    "        if( numberOfZeroTargets > numberOfOneTargets):\n",
    "            indexesToRemove.append(i)\n",
    "            \n",
    "print( 'zeros are : %s and we should remove %s indexes to balancing dataset'\n",
    "      %(numberOfZeroTargets,len(indexesToRemove)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c70d74fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rawBalancedInputs = np.delete( rawInputs, indexesToRemove, axis=0)\n",
    "# rawBalancedTargets = np.delete( rawTargets , indexesToRemove , axis = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "196236e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaledInputs = preprocessing.scale(rawInputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d32501a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffledIndex = np.arange(scaledInputs.shape[0])\n",
    "\n",
    "np.random.shuffle(shuffledIndex)\n",
    "scaledInputs\n",
    "\n",
    "shuffleInputs = scaledInputs[shuffledIndex]\n",
    "shuffleTargets = rawTargets[shuffledIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d1d4e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample count is 297 and train count is 237 and validation count is 29 and test count is 31\n"
     ]
    }
   ],
   "source": [
    "samplesCount = shuffleInputs.shape[0]\n",
    "\n",
    "trainCount = int( 0.8 * samplesCount )\n",
    "validationCount = int( 0.1 * samplesCount )\n",
    "testCount = int( samplesCount - (trainCount + validationCount) )\n",
    "\n",
    "print( 'sample count is %s and train count is %s and validation count is %s and test count is %s'\n",
    "      % ( samplesCount, trainCount, validationCount, testCount) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d965d672",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainInputs = shuffleInputs[:trainCount]\n",
    "trainTargets = shuffleTargets[:trainCount]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f254937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "validationInputs = shuffleInputs[ trainCount : trainCount + validationCount ]\n",
    "validationTargets = shuffleTargets[ trainCount : trainCount + validationCount ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "015c5181",
   "metadata": {},
   "outputs": [],
   "source": [
    "testInputs = shuffleInputs[ trainCount + validationCount : ]\n",
    "testTargets = shuffleTargets[ trainCount + validationCount : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e74496d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print( type(trainInputs) ,  type(trainTargets),\n",
    "      type(validationInputs), type(validationTargets),\n",
    "      type(testInputs), type(testTargets)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3b05d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainInputs = trainInputs.astype(float)\n",
    "trainTargets = trainTargets.astype(int)\n",
    "\n",
    "validationInputs = validationInputs.astype(float)\n",
    "validationTargets = validationTargets.astype(int)\n",
    "\n",
    "testInputs = testInputs.astype(float)\n",
    "testTargets = testTargets.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6af2ed69",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputsSize = 13\n",
    "outputSize = 2\n",
    "hiddenLayer = 50\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense( hiddenLayer , activation='relu' ),\n",
    "    tf.keras.layers.Dense( hiddenLayer , activation='relu' ),\n",
    "    tf.keras.layers.Dense( outputSize , activation='softmax' )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c991ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b64fed8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 - 1s - loss: 0.7894 - accuracy: 0.4557 - val_loss: 0.7449 - val_accuracy: 0.4138 - 921ms/epoch - 230ms/step\n",
      "Epoch 2/100\n",
      "4/4 - 0s - loss: 0.7161 - accuracy: 0.4937 - val_loss: 0.6812 - val_accuracy: 0.5172 - 35ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "4/4 - 0s - loss: 0.6559 - accuracy: 0.5907 - val_loss: 0.6324 - val_accuracy: 0.5517 - 34ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "4/4 - 0s - loss: 0.6070 - accuracy: 0.7131 - val_loss: 0.5911 - val_accuracy: 0.7586 - 33ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "4/4 - 0s - loss: 0.5645 - accuracy: 0.7932 - val_loss: 0.5543 - val_accuracy: 0.7931 - 34ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "4/4 - 0s - loss: 0.5242 - accuracy: 0.8354 - val_loss: 0.5218 - val_accuracy: 0.7931 - 36ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "4/4 - 0s - loss: 0.4879 - accuracy: 0.8270 - val_loss: 0.4926 - val_accuracy: 0.7931 - 34ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "4/4 - 0s - loss: 0.4549 - accuracy: 0.8439 - val_loss: 0.4683 - val_accuracy: 0.7931 - 33ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "4/4 - 0s - loss: 0.4263 - accuracy: 0.8481 - val_loss: 0.4473 - val_accuracy: 0.7586 - 36ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "4/4 - 0s - loss: 0.4037 - accuracy: 0.8481 - val_loss: 0.4290 - val_accuracy: 0.7586 - 40ms/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "4/4 - 0s - loss: 0.3834 - accuracy: 0.8608 - val_loss: 0.4137 - val_accuracy: 0.7586 - 41ms/epoch - 10ms/step\n",
      "Epoch 12/100\n",
      "4/4 - 0s - loss: 0.3681 - accuracy: 0.8608 - val_loss: 0.4032 - val_accuracy: 0.7586 - 37ms/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "4/4 - 0s - loss: 0.3554 - accuracy: 0.8692 - val_loss: 0.3968 - val_accuracy: 0.7586 - 36ms/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "4/4 - 0s - loss: 0.3467 - accuracy: 0.8692 - val_loss: 0.3918 - val_accuracy: 0.7931 - 34ms/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "4/4 - 0s - loss: 0.3401 - accuracy: 0.8692 - val_loss: 0.3900 - val_accuracy: 0.8276 - 34ms/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "4/4 - 0s - loss: 0.3327 - accuracy: 0.8692 - val_loss: 0.3904 - val_accuracy: 0.8276 - 36ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "4/4 - 0s - loss: 0.3283 - accuracy: 0.8692 - val_loss: 0.3897 - val_accuracy: 0.8276 - 36ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "4/4 - 0s - loss: 0.3240 - accuracy: 0.8692 - val_loss: 0.3912 - val_accuracy: 0.8276 - 34ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "4/4 - 0s - loss: 0.3196 - accuracy: 0.8692 - val_loss: 0.3916 - val_accuracy: 0.8276 - 32ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "4/4 - 0s - loss: 0.3165 - accuracy: 0.8734 - val_loss: 0.3927 - val_accuracy: 0.8276 - 39ms/epoch - 10ms/step\n",
      "Epoch 21/100\n",
      "4/4 - 0s - loss: 0.3118 - accuracy: 0.8734 - val_loss: 0.3944 - val_accuracy: 0.8276 - 34ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "4/4 - 0s - loss: 0.3085 - accuracy: 0.8776 - val_loss: 0.3973 - val_accuracy: 0.8276 - 35ms/epoch - 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b8c49b36d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochSize = 100\n",
    "batch_size =64\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=5)\n",
    "\n",
    "\n",
    "model.fit( trainInputs ,\n",
    "           trainTargets ,\n",
    "           batch_size=batch_size,\n",
    "           epochs=epochSize ,\n",
    "           validation_data=(validationInputs, validationTargets) ,\n",
    "           verbose=2,\n",
    "           callbacks=[early_stopping]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e25e870a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3255 - accuracy: 0.8387\n",
      "Test loss of our model is: 0.33. And our Test accuracy is: 83.87%\n"
     ]
    }
   ],
   "source": [
    "testLoss , testAccuracy = model.evaluate(testInputs,testTargets)\n",
    "print('Test loss of our model is: {0:.2f}. And our Test accuracy is: {1:.2f}%'.format(testLoss, testAccuracy*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b805394",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
